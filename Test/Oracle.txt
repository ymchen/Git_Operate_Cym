数据库定义
Create table
Alter table

笛卡尔积
不使用任何的匹配条件或者选取条件
存储过程
预编译的sql语句


实现某个功能的语句集

SQL语句 条件语句 循环语句

索引

加快查询速度
会减慢录入速度

索引类似目录
查询时不需要整表扫描

共享锁、排他锁  
Oracle
共享存储集群架构
可扩展性 
需要升级到功能更强大的服务器
GreenPlum
非共享存储的MPP架构 大规模并行分析架构
列存储

将数据集分布在多台机器上或者节点上，以处理大量数据。
这些节点都包含自己的存储和计算功能，从而使每个节点都可以执行查询的一部分

查询一般不用
select 都需指明需要查询的字段可以提供查询速度





Spark
是一个围绕速度、易用性和复杂分析构建的大数据处理框架
Spark作为新一代大数据计算引擎，因为内存计算的特性，
具有比hadoop更快的计算速度。本教程涉及Spark基础概念RDD，KeyValueRDD，RDD的常用Transformation和Action操作等
HDFS 文件存储

Flink主页在其顶部展示了该项目的理念：
Flink 是分布式、高性能、随时可以用以及准确的流处理应用程序打造的开源流处理框架。
Flink 分别提供了面向流式处理的接口和面向批处理的接口。Flink提供了用于流处理的DataStream API和用于批处理的DataSet API。Flink的分布式特点体现在它能够在成百上千机器上运行，它将大型计算任务分成许多小的部分每个机器执行一部分

Hadoop

MapReduce

kafka 作为消息传输队列，是一个分布式，高吞吐量。易于扩展的主题订阅、发布信息系统。



Kafka作为消息传输队列，是一个分布式的，高吞吐量，易于扩展地基于主题发布/订阅的消息系统。在现今企业级开发中，Kafka 和 Flink成为构建一个实时的数据处理系统的首选

Elasticsearch

kettle
类似之前用到datastage 之前有参加过培训，在项目组中没有实际应用。
在Kettle里，数据的单位是行，数据流就是数据行从一个步骤到另一个步骤的移动。




1.熟悉银行业务，有银行数据仓库或数据集市项目设计与开发经验；
2.精通ETL开发规范及设计，精通主流ETL工具（informatic、Datastage、kettle等），优秀的ETL性能调优经验；
3.精通关系数据库理论、数据仓库架构及原理、数据仓库实施方法论；
4.能够熟练应用一种或多种主流数据库（如：mysql、Oracle等），有hadoop开发经验优先；
5.熟悉linux系统，精通pl/sql编程，熟悉shell编程；
6.丰富的调度系统设计与开发经验,能够持续优化并提升调度系统；
7.掌握一定的数据质量管理方法论、评估模型设计、质量报表设计，能够根据数据质量要求制定数据质量探查规则并进行实施；
8.掌握一定元数据管理方法论、元数据管理设计；
9.学习能力强，拥有优秀的逻辑思维能力，具有一定的组织和协调能力及沟通交流能力，强烈的责任心和团队合作精神；
10.抗压性强，可接受随项目出差及加班。






fineReport  cognos只提供前端页面展示不支持数据修改录入

FineReport报表软件是一款纯Java编写的、集数据展示(报表)和数据录入(表单)功能于一身的企业级web报表工具，它“专业、简捷、灵活”的特点和无码理念，仅需简单的拖拽操作便可以设计复杂的中国式报表，搭建数据决策分析系统。


批量导入数据
Sqoop
kettle 抽取文档 可扩展

类似之前用到datastage 之前有参加过培训，在项目组中没有实际应用。
在Kettle里，数据的单位是行，数据流就是数据行从一个步骤到另一个步骤的移动。
扩展
Kettle的扩展性无疑是最好，因为是开源代码，可以自己开发拓展它的功能，而Informatica和Datastage由于是商业软件，基本上没有。



Sqoop(发音:skup)是一款开源的工具，主要用于在HADOOP(Hive)与传统的数据库(mysql、postgresql...)间进行数据的传递，可以将一个关系型数据库(例如 : MySQL ,Oracle ,Postgres等)中的数据导进到Hadoop的HDFS中，也可以将HDFS的数据导进到关系型数据库中


HDFS批量存储数据


Spark     计算框架 运行速度比MapReduce快上数倍，基于内存计算
MapReduce 计算框架 能够完成离线批处理功能，完成一些过滤的操作也必须经过map-reduce过程这样就必须经过shuffle，shuffle是最消耗性能，需要磁盘读写
Hive      查询引擎

任务调度

针对Hive 的Hsql查询语句的脚本，crontab 实时调度


hadoop
============================
=MapReduce 针对大数据的计算框架  Spark 、 Flink
=Hive      针对大数据的查询框架  -> HDFS   SparkSQL\Table API
=Hbase Nosql
=实时、准实时
=YARN 资源调度
=HDFS 存储  Kafka流      kettle -> HDFS
============================
Spark -> HDFS
|
Hive


SparkSQL替换的是Hive的查询引擎，Hive是一种基于HDFS的数据仓库，并且提供了基于SQL模型的，针对存了大数据的数据仓库，进行分布式交互查询的查询引擎，所以SparkSQL暂时并不能完全替代Hive，实际上，在生产环境中，SparkSQL也是针对Hive数据仓库中的数据进行查询，Spark本身自己不提供存储，自然不可能替代Hive作为数据仓库的功能。这也印证了，SparkSQL只是替代hive的查询引擎，但是hive构建数据仓库的地位，SparkSQL并不能替代。


这个架构和Spark 架构比较类似，都分为四层：存储层、部署层、核心处理引擎、high-level的API和库。

从存储层来看，Flink 同样兼容多种主流文件系统如HDFS、Amazon S3，多种数据库如HBase和多种数据流如Kafka和Flume。
从部署层来看，Flink不仅支持本地运行，还能在独立集群或者在被YARN或Mesos管理的集群上运行，也能部署在云端。
核心处理引擎就是我们刚才提到的分布式Streaming Dataflow，所有的高级API及应用库都会被翻译成包含Stream和Operator的Dataflow来执行。
Flink 提供的两个核心API就是DataSet APl和DataStream API。你没看错，名字和Spark的DataSet、DataFrame 非常相似。顾名思义，DataSet代表有界的数据集，而DataStream代表流数据。所以，DataSet API是用来做批处理的，而DataStream API是做流处理的。
也许你会问，Flink 这样基于流的模型是怎样支持批处理的？在内部，DataSet 其实也用Stream表示，静态的有界数据也可以被看作是特殊的流数据，而且DataSet与DataStream 可以无缝切换。所以，Flink的核心是DataStream。




Flink 和 Spark 对比
通过前面的学习，我们了解到，Spark和Flink都支持批处理和流处理，接下来让我们对这两种流行的数据处理框架在各方面进行对比。首先，这两个数据处理框架有很多相同点。

都基于内存计算；
都有统一的批处理和流处理APl，都支持类似SQL的编程接口；
都支持很多相同的转换操作，编程都是用类似于Scala Collection APl的函数式编程模式；
都有完善的错误恢复机制；
都支持Exactly once的语义一致性。
当然，它们的不同点也是相当明显，我们可以从4个不同的角度来看。

从流处理的角度来讲，Spark基于微批量处理，把流数据看成是一个个小的批处理数据块分别处理，所以延迟性只能做到秒级。而Flink基于每个事件处理，每当有新的数据输入都会立刻处理，是真正的流式计算，支持毫秒级计算。由于相同的原因，Spark只支持基于时间的窗口操作（处理时间或者事件时间），而Flink支持的窗口操作则非常灵活，不仅支持时间窗口，还支持基于数据本身的窗口(另外还支持基于time、count、session，以及data-driven的窗口操作)，开发者可以自由定义想要的窗口操作。
从SQL 功能的角度来讲，Spark和Flink分别提供SparkSQL和Table APl提供SQL
交互支持。两者相比较，Spark对SQL支持更好，相应的优化+、扩展和性能更好，而Flink在SQL支持方面还有很大提升空间。
从迭代计算的角度来讲，Spark对机器学习的支持很好，因为可以在内存中缓存中间计算结果来加速机器学习算法的运行。但是大部分机器学习算法其实是一个有环的数据流，在Spark中，却是用无环图来表示。而Flink支持在运行时间中的有环数据流，从而可以更有效的对机器学习算法进行运算。
从相应的生态系统角度来讲，Spark 的社区无疑更加活跃。Spark可以说有着Apache旗下最多的开源贡献者，而且有很多不同的库来用在不同场景。而Flink由于较新，现阶段的开源社区不如Spark活跃，各种库的功能也不如Spark全面。但是Flink还在不断发展，各种功能也在逐渐完善。


Spark 是基于微批量处理，是把流数据看成是一个个小的批处理数据块分别处理，延迟做到秒级。
flink 基于每个事件处理，每当有新数据输入就会立刻处理能支持毫秒级计算

spark 只支持基于时间的窗口操作 处理时间或者事件事件

对于以下场景，你可以选择 Spark。

数据量非常大而且逻辑复杂的批数据处理，并且对计算效率有较高要求（比如用大数据分析来构建推荐系统进行个性化推荐、广告定点投放等）；
基于历史数据的交互式查询，要求响应较快(impala，或者presto更优秀)；
基于实时数据流的数据处理，延迟性要求在在数百毫秒到数秒之间。
Spark完美满足这些场景的需求，而且它可以一站式解决这些问题，无需用别的数据处理平台。由于Flink是为了提升流处理而创建的平台，所以它适用于各种需要非常低延迟（微秒到毫秒级）的实时数据处理场景，比如实时日志报表分析。
而且Flink 用流处理去模拟批处理的思想，比Spark 用批处理去模拟流处理的思想扩展性更好。



Kafka是一种高吞吐量的分布式发布订阅消息系统，它可以处理消费者在网站中的所有动作流数据。 这种动作（网页浏览，搜索和其他用户的行动）是在现代网络上的许多社会功能的一个关键因素。 这些数据通常是由于吞吐量的要求而通过处理日志和日志聚合来解决。 
对于像Hadoop一样的日志数据和离线分析系统，但又要求实时处理的限制，这是一个可行的解决方案。
Kafka的目的是通过Hadoop的并行加载机制来统一线上和离线的消息处理，也是为了通过集群来提供实时的消息。

tinge  
